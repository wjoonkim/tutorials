{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y40I7vm-fMT"
      },
      "source": [
        "# BEHI 5003\n",
        "## Tutorial: Homework 1\n",
        "### Author: Won Joon Kim\n",
        "### Affiliation: Biomolecular Engineering Lab (BEL), CBE, HKUST\n",
        "\n",
        "I acknowledge the use of generative AI (Gemini Agent in Colab) in writing the code below.\n",
        "\n",
        "This notebook is a revision of the Jupyter notebook authored by Mr. Mingyi Sun (BEL, CBE, HKUST) during the Fall 2024 offering of BIEN 6930B (this course).\n",
        "\n",
        "I sincerely thank the authors and maintainers of the packages used in this tutorial!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sg02wLXjYRVN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDkl-HlZAHDe"
      },
      "source": [
        "# Background to Metropolis Monte Carlo simulation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3iNFGD3L5u0"
      },
      "source": [
        "### Monte Carlo simulation example: Coin Flip\n",
        "For a more theoretical background, you may refer to this [Wikipedia page](https://en.wikipedia.org/wiki/Monte_Carlo_method) or this [YouTube video](https://www.youtube.com/watch?v=r7cn3WS5x9c)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28m9LbJoJya9"
      },
      "source": [
        "As you are already aware, we associate coin flips as being \"fair\",\\\n",
        "i.e., the chances of getting a head or a tail are (approximately) equal (0.5).\n",
        "\n",
        "But can the computer, without being told that this is actually the case, elude this result independently?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "9WgKV4GvAKyh",
        "outputId": "98a7b91a-788a-4557-da2b-fb2754fd27db"
      },
      "outputs": [],
      "source": [
        "# Number of coin flips to simulate\n",
        "num_flips = 5000\n",
        "\n",
        "# Counter for heads\n",
        "heads_count = 0\n",
        "\n",
        "# Lists to store iteration number and estimated probability of heads for plotting\n",
        "iterations = []\n",
        "estimated_probabilities = []\n",
        "\n",
        "# Set up the plot\n",
        "plt.xlabel('Number of flips')\n",
        "plt.ylabel('Estimated Probability of Heads')\n",
        "plt.title('Estimating Probability of Heads using Monte Carlo')\n",
        "plt.axhline(0.5, color='red', linestyle='--', label='True Probability (0.5)') # Add a line for the true probability\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "# Simulate coin flips\n",
        "for i in range(1, num_flips + 1):\n",
        "    # Generate a random number between 0 and 1 from the standard normal distribution\n",
        "    random_number = random.random()\n",
        "\n",
        "    # If the number is less than 0.5, consider it heads (you can define heads as > 0.5 as well)\n",
        "    if random_number < 0.5:\n",
        "        heads_count += 1\n",
        "\n",
        "    # Calculate the estimated probability of heads at the current iteration\n",
        "    current_probability = heads_count / i\n",
        "\n",
        "    # Store the data for plotting\n",
        "    iterations.append(i)\n",
        "    estimated_probabilities.append(current_probability)\n",
        "\n",
        "    # Update the plot every 50 flips (or adjust as needed)\n",
        "    if i % 100 == 0 or i == num_flips:\n",
        "        plt.plot(iterations, estimated_probabilities, color='blue')\n",
        "        plt.axhline(0.5, color='red', linestyle='--', label='True Probability (0.5)')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend()\n",
        "        plt.xlabel('Number of flips')\n",
        "        plt.ylabel('Estimated Probability of Heads')\n",
        "        plt.title('Estimating Probability of Heads using Monte Carlo')\n",
        "        clear_output(wait=True) # Clear the previous output\n",
        "        display(plt.gcf()) # Display the current figure\n",
        "        plt.cla()\n",
        "\n",
        "\n",
        "\n",
        "# show results\n",
        "print(\"Final results:\")\n",
        "print(f\"Number of flips: {num_flips}\")\n",
        "print(f\"Number of heads: {heads_count}\")\n",
        "print(f\"Estimated probability of heads: {current_probability}\")\n",
        "# After the loop, make sure the final plot is displayed\n",
        "plt.plot(iterations, estimated_probabilities, color='blue')\n",
        "plt.axhline(0.5, color='red', linestyle='--', label='True Probability (0.5)')\n",
        "plt.xlabel('Number of flips')\n",
        "plt.ylabel('Estimated Probability of Heads')\n",
        "plt.title('Estimating Probability of Heads using Monte Carlo')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxZG5KWsLPHF"
      },
      "source": [
        "### Metropolis Monte Carlo simulation example: 1D Random Walk with a Potential\n",
        "For a more theoretical background, you may refer to this [Wikipedia page](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) or [YouTube video](https://www.youtube.com/watch?v=Jr1GdNI3Vfo).\n",
        "\n",
        "Comments have been added to the code for explanation of each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RkEg9p9PWuNw"
      },
      "outputs": [],
      "source": [
        "# Define the potential function (e.g., a simple quadratic potential)\n",
        "# Think of this as the \"hilly landscape\" - the potential function tells us the \"height\" at any given \"position\".\n",
        "def potential(x):\n",
        "    return x**2\n",
        "\n",
        "#@markdown Number of Monte Carlo steps (how many steps we take in our search)\n",
        "n_steps = 5000  #@param {type:\"raw\"}\n",
        "\n",
        "#@markdown Temperature parameter (kT) - this influences how likely we are to accept moves that go uphill.\n",
        "kT = 0.5 #@param {type:\"raw\"}\n",
        "#@markdown - A higher temperature means we are more likely to accept uphill moves, allowing us to explore more.\n",
        "#@markdown - A lower temperature means we are less likely to accept uphill moves, making us more likely to settle in a low point.\n",
        "\n",
        "#@markdown Initial position (where we start our search in the landscape)\n",
        "current_position = 5.0 #@param {type:\"raw\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pMQ3qEQURCxd",
        "outputId": "4c1f47fa-9cd2-4a85-e519-68ab1ecf34b2"
      },
      "outputs": [],
      "source": [
        "# List to store the history of positions for the trajectory plot and marginal histogram\n",
        "position_history = [current_position]\n",
        "\n",
        "# Set up the plots (two subplots and a marginal axis)\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "gs = fig.add_gridspec(2, 2, width_ratios=[4, 1], height_ratios=[2, 3]) # Define grid for subplots with ratios - increased height of the first row\n",
        "\n",
        "# Plot 1: Traveler on the Potential Function (Top-left)\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "x_values = np.linspace(-5, 5, 100) # Generate x values to plot the potential\n",
        "ax1.plot(x_values, potential(x_values), label='Potential Function')\n",
        "ax1.set_xlabel('Position')\n",
        "ax1.set_ylabel('Potential Energy')\n",
        "ax1.set_title('Metropolis Monte Carlo 1D Random Walk')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "# Create a point to represent the traveler\n",
        "traveler_point, = ax1.plot([current_position], [potential(current_position)], 'ro') # 'ro' for red circle\n",
        "\n",
        "# Plot 2: Position Trajectory (Bottom-left)\n",
        "ax2 = fig.add_subplot(gs[1, 0]) # Removed sharex=ax1\n",
        "ax2.set_xlabel('Monte Carlo Step')\n",
        "ax2.set_ylabel('Position')\n",
        "ax2.set_title('Traveler Position Trajectory')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "trajectory_line, = ax2.plot(position_history, color='blue')\n",
        "plt.setp(ax1.get_xticklabels(), visible=False) # Hide x-axis labels on the top plot\n",
        "\n",
        "# Plot 3: Marginal Histogram of Positions (Bottom-right)\n",
        "ax3 = fig.add_subplot(gs[1, 1], sharey=ax2) # Share y-axis with the trajectory plot\n",
        "ax3.set_xlabel('Frequency')\n",
        "ax3.set_title('Position Distribution')\n",
        "plt.setp(ax3.get_yticklabels(), visible=False) # Hide y-axis labels on the marginal plot\n",
        "\n",
        "\n",
        "plt.tight_layout() # Adjust layout to prevent overlapping titles/labels\n",
        "\n",
        "# Metropolis Monte Carlo simulation\n",
        "for step in range(n_steps):\n",
        "    # Propose a new position (random walk step)\n",
        "    # We randomly suggest moving to a new spot in the landscape.\n",
        "    # Propose a move by adding a random number from a normal distribution - this determines how big and in what direction our proposed step is.\n",
        "    proposed_position = current_position + random.gauss(0, 1)\n",
        "\n",
        "    # Calculate the potential energy at the current and proposed positions\n",
        "    # We find out the \"height\" of our current spot and the \"height\" of the proposed new spot.\n",
        "    current_energy = potential(current_position)\n",
        "    proposed_energy = potential(proposed_position)\n",
        "\n",
        "    # Calculate the change in energy\n",
        "    # We see if the proposed move goes uphill (positive dE) or downhill (negative dE).\n",
        "    delta_E = proposed_energy - current_energy\n",
        "\n",
        "    # Metropolis acceptance criterion\n",
        "    # This is the rule for deciding whether to move to the proposed spot.\n",
        "    # Calculate the probability of accepting the proposed move\n",
        "    # If the energy decreases (delta_E < 0), P_accept is min(exp(-negative/kT), 1) which is 1 - we always accept moves that go downhill.\n",
        "    # If the energy increases (delta_E >= 0), P_accept is exp(-positive/kT) - we might accept uphill moves, but the probability is lower for larger uphill steps and lower temperatures.\n",
        "    P_accept = min(1, np.exp(-delta_E / kT))\n",
        "\n",
        "    # Accept or reject the proposed move\n",
        "    # We generate a random number and compare it to the acceptance probability.\n",
        "    # Generate a random number between 0 and 1\n",
        "    random_accept = random.random()\n",
        "    # If the random number is less than P_accept, accept the move - if our random chance is less than the probability of accepting, we move.\n",
        "    if random_accept < P_accept:\n",
        "        current_position = proposed_position # We move to the new position\n",
        "\n",
        "    # Store the current position for the trajectory plot and marginal histogram\n",
        "    position_history.append(current_position)\n",
        "\n",
        "    # Update the plots every 100 steps (or adjust as needed)\n",
        "    if step % 100 == 0 or step == n_steps - 1:\n",
        "        # Update traveler position on the first plot\n",
        "        traveler_point.set_data([current_position], [potential(current_position)])\n",
        "\n",
        "        # Update trajectory on the second plot\n",
        "        trajectory_line.set_data(range(len(position_history)), position_history)\n",
        "        ax2.set_xlim(0, len(position_history)) # Adjust x-axis limit of trajectory plot\n",
        "        #ax2.set_ylim(min(position_history) - 0.5, max(position_history) + 0.5) # Adjust y-axis limit - removed because sharing y-axis with marginal plot\n",
        "\n",
        "        # Update the marginal histogram\n",
        "        ax3.cla() # Clear the previous histogram\n",
        "        ax3.hist(position_history, bins=50, orientation='horizontal', density=True, color='green', alpha=0.5)\n",
        "        ax3.set_xlabel('Density')\n",
        "        ax3.set_title('Position Distribution')\n",
        "        plt.setp(ax3.get_yticklabels(), visible=False)\n",
        "\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        display(fig) # Display the entire figure with both subplots and marginal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJSVG0qoUFmj"
      },
      "source": [
        "From the marginal density histogram (green) on the right of the bottom subplot, we can observe that the original normal distribution can be \"regenerated\" from the trajectory of the traveler!\n",
        "\n",
        "This again reinforces the law of large numbers!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bioinfo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
